---
title: "PSI Independent Project C15311966"
output: html_notebook
---



```{r Setup}
# dataset used
# https://www.sciencedirect.com/science/article/pii/S2352340920304315#utbl0001
# download @ https://data.mendeley.com/datasets/83tcx8psxv/1

needed_packages <- c("tidyverse", "readxl", "feather", "car", "nortest", "skimr")                      
# Extract not installed packages
not_installed <- needed_packages[!(needed_packages %in% installed.packages()[ , "Package"])]    
# Install not installed packages
if(length(not_installed)) install.packages(not_installed)

library(tidyverse)
library(readxl) # read xlsx
library(feather) # file format lib
library(skimr) # summary statistics for larger data sets
library(car)
library(nortest)
df = read_excel('idepen_proj_stats.xlsx')

```

```{r Initial Data Exploration}

# basic exploration
head(df)
summary(df)
glimpse(df)
colnames(df)
# how many missing values are in each col
map(df , ~sum(is.na(.)))

# looking at cols with potential problems 
unique(df$PHONE)
unique(df$...10) # found potential issues

unique(df$JOB) # found potential issues
unique(df$UNIVERSITY)
unique(df$SCHOOL_NAT)
unique(df$ACADEMIC_PROGRAM)

unique(df$EDU_FATHER) 
# found potential issues a field with a value of 0, 
# however this could indicate something else such as an absent parent, 
# it will be left as is
unique(df$OCC_FATHER) # found potential issues, ^
unique(df$EDU_MOTHER) # found potential issues, ^
unique(df$OCC_MOTHER) # found potential issues, ^


#########################
# variables of interest #
#########################

colnames(df)

# looking for odd values which can be found easily via unique, such as negative values on exams etc

unique(df$SISBEN) # found potential issues
unique(df$INTERNET)
unique(df$TV)
unique(df$COMPUTER)
unique(df$WASHING_MCH)
unique(df$CAR)
unique(df$MIC_OVEN)
unique(df$DVD)
unique(df$FRESH)
unique(df$PHONE)
unique(df$MOBILE)

# Saber 11 EXAMS - no issues found
unique(df$MAT_S11) # maths
unique(df$CR_S11) # critical reading
unique(df$CC_S11) # citizen competencies
unique(df$BIO_S11) # biology
unique(df$ENG_S11) # communication in English

# SABER PRO EXAMS - no issues found
unique(df$CR_PRO) # critical reading
unique(df$QR_PRO) # quantitative reasoning
unique(df$CC_PRO) # citizen competencies
unique(df$WC_PRO) # written communication
unique(df$ENG_PRO) # communication in English


```

```{r Data Cleaning}


# column is completely empty and serves no purpose 
df = df[,!names(df) %in% c("...10")]

# fixing inconsistency
df$SISBEN[df$SISBEN == "0"] = "Level 0"
df$SISBEN[df$SISBEN == "It is not classified by the SISBEN"] = "Level NA"
df$SISBEN[df$SISBEN == "Esta clasificada en otro Level del SISBEN"] = "Level NA"

df$JOB[df$JOB == "0"] = "No"

# saving file into feather while working on project
# it offers faster load times, however its not used
# to store data long term
write_feather(df, 'idepen_proj_stats.feather')
df = read_feather('idepen_proj_stats.feather')

```

```{r Testing for normality-pro exams}

# fragmenting data
df_pro_exams =  data.frame(df$CR_PRO, df$QR_PRO, df$CC_PRO, df$WC_PRO, df$ENG_PRO)
summary(df_pro_exams)
# anderson-darling normality test is used over shapiro-wilks
# because it has a limitation of 5000 records 
# for comparison both give the same result
shapiro.test(df_pro_exams$df.CR_PRO[0:5000])
ad.test(df_pro_exams$df.CR_PRO)
ad.test(df_pro_exams$df.QR_PRO)
ad.test(df_pro_exams$df.CC_PRO)
ad.test(df_pro_exams$df.WC_PRO)
ad.test(df_pro_exams$df.ENG_PRO)
# p < 2.2e-16

qqPlot(df_pro_exams$df.CR_PRO)
qqPlot(df_pro_exams$df.QR_PRO)
qqPlot(df_pro_exams$df.CC_PRO)
qqPlot(df_pro_exams$df.WC_PRO)
qqPlot(df_pro_exams$df.ENG_PRO)

hist(df_pro_exams$df.CR_PRO)
hist(df_pro_exams$df.QR_PRO)
hist(df_pro_exams$df.CC_PRO)
hist(df_pro_exams$df.WC_PRO)
hist(df_pro_exams$df.ENG_PRO)

Boxplot(df_pro_exams$df.CR_PRO)
Boxplot(df_pro_exams$df.QR_PRO)
Boxplot(df_pro_exams$df.CC_PRO)
Boxplot(df_pro_exams$df.WC_PRO)
Boxplot(df_pro_exams$df.ENG_PRO)

# from the visualizations, p-value and a-value the pro exams are NOT normally distributed

```

```{r Testing for normality-saber exams}

df_saber_exams =  data.frame(df$MAT_S11, df$CR_S11, df$CC_S11, df$BIO_S11, df$ENG_S11)
summary(df_saber_exams)

ad.test(df_saber_exams$df.MAT_S11)
ad.test(df_saber_exams$df.CR_S11)
ad.test(df_saber_exams$df.CC_S11)
ad.test(df_saber_exams$df.BIO_S11)
ad.test(df_saber_exams$df.ENG_S11)
# p < 2.2e-16

hist(df_saber_exams$df.MAT_S11)
hist(df_saber_exams$df.CR_S11)
hist(df_saber_exams$df.CC_S11)
hist(df_saber_exams$df.BIO_S11)
hist(df_saber_exams$df.ENG_S11)


Boxplot(df_saber_exams$df.MAT_S11)
Boxplot(df_saber_exams$df.CR_S11)
Boxplot(df_saber_exams$df.CC_S11)
Boxplot(df_saber_exams$df.BIO_S11)
Boxplot(df_saber_exams$df.ENG_S11)

# even though the p value in normality test doesnt confirm normality, the low A value and
# visualizations confirm a normally distribution for most exams

```

```{r}

```