{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your Own Evaluation Framework\n",
    "\n",
    "In this lab exercise we're going to build our own model evaluation framework. Pretty much every machine learning experiment follows the same template\n",
    "\n",
    "1. Load a dataset and split into train and test sets\n",
    "2. Create a model and train it on your training data\n",
    "3. Predict the labels for the test data and compare with the actual labels\n",
    "4. Record whatever evaluation metrics you are using\n",
    "\n",
    "For this example we're going to use the wine dataset [available from the UCI machine learning repository](https://archive.ics.uci.edu/ml/datasets/wine+quality). The csv file for this dataset is available in Brightspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our data into X and y\n",
    "\n",
    "The first thing we want to do when we load up a dataset is separate the X and Y data. If we accidentally leave our labels in the dataset when we train our models we'll get incredible results! They won't hold up in the real world though!\n",
    "\n",
    "The pandas **pop()** method lets us extract a column from a dataset. We're using pop() here to pull the wine column out separately as our label column. Unlike most python functions, the **pop()** method has a side effect; as well as returning the column to us, it removes it from the original dataframe. Python usually avoids functions like this because it can be difficult to see what's happening with them, but popping the label column is such a common use case for machine learning that it's survived here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Data\n",
      "     Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
      "0      14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
      "1      13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
      "2      13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
      "3      14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
      "4      13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
      "..       ...         ...   ...   ...  ...      ...         ...   \n",
      "173    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
      "174    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
      "175    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
      "176    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
      "177    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
      "\n",
      "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
      "0                    0.28     2.29       5.64  1.04  3.92     1065  \n",
      "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
      "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
      "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
      "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
      "..                    ...      ...        ...   ...   ...      ...  \n",
      "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
      "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
      "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
      "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
      "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
      "\n",
      "[178 rows x 13 columns]\n",
      "Labels\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "\n",
    "y = X.pop('Wine').values\n",
    "\n",
    "print(\"X Data\")\n",
    "print(X)\n",
    "\n",
    "print(\"Labels\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting our Data into Train and Test\n",
    "\n",
    "If we're going to evaluate our model we need one portion of the data to train our model and another portion of the data to test it. Sci-kit-learn provides a convenience function to do this for us but we're going to have a go at implementing this functionality ourselves first.\n",
    "\n",
    "We want to write a function which takes an dataframe and an array of labels, and returns\n",
    "\n",
    "* 2 dataframes, one training set with X% of the data and one test set with the remainder\n",
    "* 2 label arrays, one training set with X% of the data and one test set with the remainder\n",
    "\n",
    "Our function takes a propotion between 0 and 1 and splits the training and test set accordingly. Our first job is to work out how many rows belong to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X: pd.DataFrame, y: np.array, train_proportion: float):\n",
    "    \n",
    "    # We use floor here (or ceiling) to ensure that we take a whole number of rows\n",
    "    num_train = math.floor(len(X) * train_proportion)\n",
    "    \n",
    "    # Using [start:end] indexing, this takes all rows from 0 up to num_train (exclusive)\n",
    "    X_train = X.iloc[:num_train,]\n",
    "    # For our test set we'll take everything from num_train up to the end of the dataframe\n",
    "    X_test = X.iloc[num_train:,]\n",
    "    \n",
    "    # Do the same with the y-data (note this is just a regular array and so we don't need .iloc\n",
    "    # we can index it directly)\n",
    "    y_train = y[:num_train]\n",
    "    y_test = y[num_train:]\n",
    "    \n",
    "    # Use the comma operator to return all 4 values from our function\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above returns the right number of instances for train and test, but we're just taking the first N rows of the dataframe. This can be a problem, as dataframes are often ordered by the label, so our model might be missing a substantial number of rows from one class. It's always important to ensure that we randomize before sampling.\n",
    "\n",
    "We can use the numpy **random.shuffle()** to randomly shuffle our array before splitting it. This will make sure that we select random rows from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def split_data(X: pd.DataFrame, y: np.array, train_proportion: float):\n",
    "    \n",
    "    # It's important to make a copy here.\n",
    "    # Check what happens if you don't do it. Shuffle the y array rather than a copy\n",
    "    # of it and print the contents of y before and after calling this function\n",
    "    X_shuffle = shuffle(X.copy())\n",
    "    y_shuffle = shuffle(y.copy())\n",
    "    \n",
    "    \n",
    "    # We use floor here (or ceiling) to ensure that we take a whole number of rows\n",
    "    num_train = math.floor(len(X) * train_proportion)\n",
    "    \n",
    "    # Using [start:end] indexing, this takes all rows from 0 up to num_train (exclusive)\n",
    "    X_train = X_shuffle.iloc[:num_train,]\n",
    "    # For our test set we'll take everything from num_train up to the end of the dataframe\n",
    "    X_test = X_shuffle.iloc[num_train:,]\n",
    "    \n",
    "    # Do the same with the y-data (note this is just a regular array and so we don't need .iloc\n",
    "    # we can index it directly)\n",
    "    y_train = y_shuffle[:num_train]\n",
    "    y_test = y_shuffle[num_train:]\n",
    "    \n",
    "    # Use the comma operator to return all 4 values from our function\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now making sure that our choice of train and test is properly randomized. However, because we've called shuffle twice on two separate arrays, these arrays will no longer correspond to each other and our labels will all be wrong.\n",
    "\n",
    "Whenever we generate a random sequence of numbers, we can ensure that we get the same sequence across multiple calls by supplying a **random seed** or **random state**. Numpy provides its own RandomState class. We're going to use this to make sure we have the same result when shuffling both the X and y data. We'll allow the caller to pass in a random seed when they call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def split_data(X: pd.DataFrame, y: np.array, train_proportion: float, random_seed: int):\n",
    "    \n",
    "    # It's important to make a copy here.\n",
    "    # Check what happens if you don't do it. Shuffle the y array rather than a copy\n",
    "    # of it and print the contents of y before and after calling this function\n",
    "    \n",
    "    rs = RandomState(random_seed)\n",
    "    X_shuffle = shuffle(X.copy(), random_state=rs)\n",
    "    \n",
    "    # reset the random state so we get the same result from shuffle\n",
    "    rs = RandomState(random_seed)\n",
    "    y_shuffle = shuffle(y.copy(), random_state=rs)\n",
    "    \n",
    "    \n",
    "    # We use floor here (or ceiling) to ensure that we take a whole number of rows\n",
    "    num_train = math.floor(len(X) * train_proportion)\n",
    "    \n",
    "    # Using [start:end] indexing, this takes all rows from 0 up to num_train (exclusive)\n",
    "    X_train = X_shuffle.iloc[:num_train,]\n",
    "    # For our test set we'll take everything from num_train up to the end of the dataframe\n",
    "    X_test = X_shuffle.iloc[num_train:,]\n",
    "    \n",
    "    # Do the same with the y-data (note this is just a regular array and so we don't need .iloc\n",
    "    # we can index it directly)\n",
    "    y_train = y_shuffle[:num_train]\n",
    "    y_test = y_shuffle[num_train:]\n",
    "    \n",
    "    # Use the comma operator to return all 4 values from our function\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.8, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we prefer we can use scikit-learn to do the job of splitting the dataset for us. It's often a good idea to let the libraries do the hard work, but it's important to know how to implement something yourself if your needs aren't quite met by the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: 142 rows, 13 columns\n",
      "X Test: 36 rows, 13 columns\n",
      "y Train: 142 rows\n",
      "y Test: 36 rows\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.random import RandomState\n",
    "\n",
    "\n",
    "random_seed = 13\n",
    "rs = RandomState(random_seed)\n",
    "\n",
    "# train_test_split() expects the X and y parameters to correspond to each other, meaning\n",
    "# that the first value in y is the label for the first row in X. This function will \n",
    "# ensure that corresponding values aren't changed.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "\n",
    "def get_shape(df: pd.DataFrame):\n",
    "    return f\"{df.shape[0]} rows, {df.shape[1]} columns\"\n",
    "\n",
    "print(f\"X Train: {get_shape(X_train)}\")\n",
    "print(f\"X Test: {get_shape(X_test)}\")\n",
    "print(f\"y Train: {len(y_train)} rows\")\n",
    "print(f\"y Test: {len(y_test)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the Dataset Together\n",
    "\n",
    "We've seen that in order to get a dataset ready for machine learning we need to\n",
    "\n",
    "* Read the dataset from a file\n",
    "* split off the label column\n",
    "* split the data into train and test\n",
    "\n",
    "This is generally going to be the case for any type of dataset so we can make our lives much easier by creating a function to do this work for us. The function below takes everything we've done so far and puts it together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath: str, label_column: str, train_proportion: float, random_seed: int):\n",
    "    df = pd.read_csv(filepath)\n",
    "    label = df.pop(label_column)\n",
    "    X_train, X_test, y_train, y_test = split_data(df, label, train_proportion, random_seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_dataset('wine.csv', 'Wine', 0.8, 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating the Model\n",
    "\n",
    "Now that we've split our data into X and y and train and test we're ready to train and evaluate our model. No matter what model we're evaluating or what dataset we're using, the steps here will always be the same.\n",
    "\n",
    "1. Train the model using X_train and y_train\n",
    "2. Make a prediction for each item in X_test\n",
    "3. Compare the predictions (y_pred) with the actual labels (y_test) and calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# To train the model we pass in both the data and the labels\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# We ask the model to predict labels for each of our test rows\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# The numpy equal function takes 2 arrays and for each element returns true if the\n",
    "# corresponding elements are equal, false otherwise. If y_pred[i] == y_test[i] then\n",
    "# the model was correct\n",
    "correct = np.equal(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of correct predictions isn't very useful on its own. At a minimum we'll want to find the percentage of predictions which were correct (*i.e.* the misclassification rate). The following function will calculate the misclassification from looking at y_pred and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_misclassification_rate(y_pred, y_test):\n",
    "    correct = np.equal(y_pred, y_test)\n",
    "    # By summing a boolean array we count the number of True values\n",
    "    total_correct = sum(correct)\n",
    "    # Getting the length gives us the total number of predictions made\n",
    "    total_predictions = len(correct)\n",
    "    # Formular for misclassification rate\n",
    "    return total_correct / total_predictions\n",
    "\n",
    "get_misclassification_rate(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Code Reusable\n",
    "\n",
    "Every evaluation is going to look the same, so by writing a function to train and evaluate the model we can make it very easy for ourselves to compare additional models. In order to train and evaluate a model we'll need\n",
    "\n",
    "* X_train\n",
    "* X_test\n",
    "* y_train\n",
    "* y_test\n",
    "* a model\n",
    "\n",
    "Let's create a function taking each of these as a parameter and returning the misclassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.9722222222222222\n",
      "DecisionTreeClassifier: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    " def get_misclassification_rate(y_pred, y_test):\n",
    "    correct = np.equal(y_pred, y_test)\n",
    "    # By summing a boolean array we count the number of True values\n",
    "    total_correct = sum(correct)\n",
    "    # Getting the length gives us the total number of predictions made\n",
    "    total_predictions = len(correct)\n",
    "    # Formular for misclassification rate\n",
    "    return total_correct / total_predictions\n",
    "    \n",
    "# There's no easy way to specify a type for all sklearn models so we use the keyword **any**, meaning\n",
    "# any type is allowed here. However, in order for the function to work the model will need to have a .fit() method and a .predict() method\n",
    "def evaluate_model(X_train: pd.DataFrame, X_test: np.array, y_train: pd.DataFrame, y_test: np.array, model: any) -> float:\n",
    "\n",
    "    # To train the model we pass in both the data and the labels\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # We ask the model to predict labels for each of our test rows\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return get_misclassification_rate(y_pred, y_test)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [LogisticRegression(max_iter=200000), DecisionTreeClassifier()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_dataset('wine.csv', 'Wine', 0.8, 13)\n",
    "for model in models:\n",
    "    # we're digging into the SKLearn model to get its name\n",
    "    print(f\"{type(model).__name__}: {evaluate_model(X_train, X_test, y_train, y_test, model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
