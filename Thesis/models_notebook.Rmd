---
title: "R Notebook"
output: html_notebook
---



```{r - setup, reload data}

# QVT setup 
library(irr)
library(ROCR)
library(infotheo)


# install.packages("penalizedSVM")

library(sparseSVM)
library(SVMMaj)
library(WeightSVM)
library(e1071) # SVM package 
library(kernlab) # SVM package/s - has multiple libs such as LiblineaR, kernlab, e1071, obliqueRF
library(penalizedSVM) # needed for Smoothly clipped absolute deviation penalty (SCAD)
library(Metrics)


# Notes for kernlab - seems to have e1071 svm impl too aswell as other libraries
# https://topepo.github.io/caret/available-models.html 
# https://stackoverflow.com/questions/18911338/vastly-different-results-for-svm-model-using-e1071-and-caret
# https://www.thekerneltrip.com/statistics/kernlab-vs-e1071/#:~:text=While%20kernlab%20implements%20kernel%2Dbased,bagged%20clustering%2C%20naive%20Bayes%20classifier. 





# library(rdwd) # DWD package
library(sdwd) # SparseDWD
library(kerndwd)
library(DWDLargeR)

# Other
library(caret) # data split - https://rdrr.io/rforge/caret/man/createDataPartition.html
library(mlbench) # https://cran.r-project.org/web/packages/mlbench/mlbench.pdf
library(ggplot2) # lib for making plots
library(Boruta)
library(glmnet)
library(elasticnet)
library(randomForest)


# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
library(kableExtra) # Used to generate report ready tables

getwd()


#y_labels_train = read.csv(file='mlsp-2014-mri/Train/train_labels.csv', head=TRUE, sep=",") # this is your y var
# Convert 'Class' into an unordered categorical variable, and assign labels
# to each level.

#y_labels_train$Class = factor(y_labels_train$Class) 

# labels=c('Healthy_Control','Schizophrenic_Patient')
# 46 control # 40 patient 

############################
# loading and merging data #
############################

mlsp_test = read.csv(file='mlsp_test.csv',head=TRUE,sep=",")
mlsp_train = read.csv(file='mlsp_train.csv',head=TRUE,sep=",")
rpart_features_data = read.csv(file='rpart_features_data.csv',head=TRUE,sep=",")
Boruta_features_data_without_tentative = read.csv(file='Boruta_features_data_without_tentative.csv',head=TRUE,sep=",")
LASSO_features_data = read.csv(file='LASSO_features_data.csv',head=TRUE,sep=",")
RFE_features_data = read.csv(file='RFE_features_data.csv',head=TRUE,sep=",")
RRF_features_data = read.csv(file='RRF_features_data.csv',head=TRUE,sep=",")


#FNC_train = read.csv(file='mlsp-2014-mri/Train/train_FNC.csv',head=TRUE,sep=",")
#SBM_train = read.csv(file='mlsp-2014-mri/Train/train_SBM.csv',head=TRUE,sep=",")
#train_data = merge(FNC_train, SBM_train, by = "Id")
#train_data = merge(train_data, y_labels_train, by="Id")

# These dont have lables so its pointless to use for testing
#SBM_test = read.csv(file='mlsp-2014-mri/Test/test_SBM.csv',head=TRUE,sep=",")
#FNC_test = read.csv(file='mlsp-2014-mri/Test/test_FNC.csv',head=TRUE,sep=",")
#test_data = merge(FNC_test, SBM_test, by = "Id")
#test_data = test_data[,2:411]
#write.csv(test_data, "mlsp_test.csv", row.names = FALSE)
#######################################
# data 80% - 20% split for train-test #
#######################################
#train_data = train_data[,2:412]
#write.csv(train_data, "mlsp_train.csv", row.names = FALSE)
# https://rdrr.io/rforge/caret/man/createDataPartition.html



# get indices for 70% of the data set
tmp_data = createDataPartition(y = train_data$Class, p = 0.7, list=FALSE)

# separate test and training sets
train_sample_data = train_data[tmp_data,]
test_sample_data = train_data[-tmp_data,]


set_new_data_after_feature_selection=function(train_data){
  tmp_data = createDataPartition(y = train_data$Class, p = 0.7, list=FALSE)
  train_sample_data = RRF_features_data[tmp_data,]
  test_sample_data = RRF_features_data[-tmp_data,]
}

data_split=function(input_ds){
  tmp_data = createDataPartition(y = input_ds$Class, p = 0.7, list=FALSE)
  return(tmp_data)
}

get_top_features=function(features, size, feature_names){
  
  if(missing(feature_names)){
    var_imp = varImp(features)
    tmp_df = data.frame(var_imp[1])
  
    if(missing(size)) {
          feature_names = rownames(tmp_df)[order(tmp_df$Overall, decreasing=TRUE)]
  
      } else {
          feature_names = rownames(tmp_df)[order(tmp_df$Overall, decreasing=TRUE)][1:size]
  
      }
  }
  
  features_subset_df = subset(train_data, select = feature_names)
  return(features_subset_df)

}

get_data_for_kaggle_score=function(preds){
  sample_sub = read.csv(file='mlsp-2014-mri/submission_example.csv', head=TRUE,sep=",")
  sample_sub$Probability = preds
  write.csv(sample_sub,file='new_submission.csv', row.names=FALSE)
}

get_test_metrics=function(test_sample_data, preds){
  
  #sse = sse(as.numeric(test_sample_data$Class), preds)
  #RMSE = RMSE(as.numeric(test_sample_data$Class), preds)
  #mse = mse(as.numeric(test_sample_data$Class), preds)
  #R2 = R2(preds, as.numeric(test_sample_data$Class))
  auc = Metrics::auc(test_sample_data$Class, preds)
  cf = confusionMatrix(as.factor(preds), as.factor(test_sample_data$Class), mode="everything", positive = "1")
  
  print(cf)
  print(paste0("AUC is: ", round(auc, 2)))
  #print(paste0("SSE is: ", sse))
  #print(paste0("RMSE is: ", RMSE))
  #print(paste0("mse is: ", mse))
  #print(paste0("R2 is: ", round(R2, 2)))
  
}


```


```{r - Regularized Random Forest - DONE - TODO go higher than 25}

# 0 = 'Healthy Control', 1 = 'Schizophrenic Patient'

#############################
# Regularized Random Forest #
#############################
# making a dummy var, something you'd use in general linear regression

#tmp_data = cbind(train_data, rnorm(1:dim(train_data)[1]))
#colnames(tmp_data)[412] = 'dummy_var'
#cols_list = colnames(tmp_data)
#cols = cols_list[cols_list != "Id"]
#data_with_dummy_var = subset(tmp_data, select=c(cols))


size=25
RRF = train(Class ~ ., data=train_data, method="RRF")
RRF_features = varImp(RRF)
feature_names = data.frame(RRF_features[1])
feature_names = rownames(feature_names)[order(feature_names$Overall, decreasing=TRUE)][1:size]
feature_names = append(feature_names, "Class")
feature_names

# plot(RRF_features, top = size, main='Variable Importance')
size= 26
RRF_features_data =  get_top_features(RRF, size, feature_names)
# write.csv(RRF_features_data, "RRF_features_data.csv", row.names = FALSE)

tmp_data = createDataPartition(y = RRF_features_data$Class, p = 0.7, list=FALSE)
train_sample_data = RRF_features_data[tmp_data,]
test_sample_data = RRF_features_data[-tmp_data,]


```


```{r - RFE - DONE}

# TODO investigate what to do with this if boruta is being used

#######
# RFE # 
#######
# https://topepo.github.io/caret/feature-selection-using-genetic-algorithms.html


# 203 was the highest you can go without including terms that lower model preformance 
train_control = rfeControl(functions=rfFuncs, method = "cv", number = 10)
size = 203

result_rfe_all_features = rfe(x = train_data[,1:411], 
                   y = train_data$Class, 
                   # sizes = 410, # best all features
                   # 410 found that some features were lowering accuracy
                   sizes = size,
                   rfeControl = train_control)

#predictors(result_rfe_all_features)

result_rfe_all_features$variables

RFE_features_data = get_top_features(result_rfe_all_features, size)
# 

tmp_data = createDataPartition(y = RFE_features_data$Class, p = 0.7, list=FALSE)
train_sample_data_rfe = RFE_features_data[tmp_data,]
test_sample_data_rfe = RFE_features_data[-tmp_data,]
train_sample_data = train_sample_data_rfe
test_sample_data = test_sample_data_rfe

Varimp_data_all = data.frame(feature = row.names(varImp(result_rfe_all_features))[1:size],
                          importance = varImp(result_rfe_all_features)[1:size, 1])

ggplot(data=Varimp_data_all, 
       aes(x = reorder(feature, -importance), y = importance, fill = feature)) +
  geom_bar(stat="identity") + labs(x = "Features", y = "Variable Importance") + 
  # geom_text(aes(label = round(importance, 1)), vjust=1.6, color="white", size=4) + 
  theme_bw() + theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))




```


```{r - LASSO - DONE}
#########
# LASSO #
#########
size = 20
lasso_cv = cv.glmnet(as.matrix(train_data[,1:410]), as.double(train_data$Class), family='binomial', alpha=1, parallel=TRUE, standardize=TRUE, type.measure='mse', keep=T)

plot(lasso_cv)
# lasso_cv$lambda.min
cat('Min Lambda: ', lasso_cv$lambda.min, '\n 1Sd Lambda: ', lasso_cv$lambda.1se)

# could use multinomial if you can extract names from this
# coef(lasso_cv, s=lasso_cv$lambda.min)


# family has to be binomial to get coef otherwise multinomial
df_lass_cv_coef = round(as.matrix(coef(lasso_cv, s=lasso_cv$lambda.min)), 4)

# See all contributing variables/not shrunk to 0
df_lass_cv_coef_survivors = df_lass_cv_coef[df_lass_cv_coef[, 1] != 0, ]


feature_names = rownames(df_lass_cv_coef)[order(df_lass_cv_coef, decreasing=TRUE)][1:size]
feature_names = append(feature_names, "Class")
feature_names = feature_names[feature_names != "(Intercept)"]
feature_names
LASSO_features_data =  get_top_features(lasso_cv, size, feature_names)
write.csv(LASSO_features_data, "LASSO_features_data.csv", row.names = FALSE)

tmp_data = createDataPartition(y = LASSO_features_data$Class, p = 0.7, list=FALSE)
train_sample_data = LASSO_features_data[tmp_data,]
test_sample_data = LASSO_features_data[-tmp_data,]

```


```{r - Boruta - DONE}

##########
# Boruta #
##########

boruta_output = Boruta(Class ~ ., data=train_sample_data, doTrace=0)  

#boruta_signif_with_tentative = getSelectedAttributes(boruta_output, withTentative = TRUE)

#imps_with_tentative = attStats(boruta_output)
#imps2_with_tentative = imps_with_tentative[imps_with_tentative$decision != 'Rejected', c('meanImp', 'decision')]
#head(imps2_with_tentative[order(-imps2_with_tentative$meanImp), ]) 
#Boruta_features_data_with_tentative = subset(train_sample_data, select = rownames(imps2_with_tentative))

##########################
# no tentative variables #
##########################

boruta_without_tentative = TentativeRoughFix(boruta_output)
boruta_signif_without_tentative = getSelectedAttributes(boruta_output, withTentative = FALSE)
boruta_signif_2 = getSelectedAttributes(boruta_output)

imps_without_tentative = attStats(boruta_without_tentative)
imps2_without_tentative = imps_without_tentative[imps_without_tentative$decision != 'Rejected', c('meanImp', 'decision')]
head(imps2_without_tentative[order(-imps2_without_tentative$meanImp), ]) 
feature_names = rownames(imps2_without_tentative)
feature_names = append(feature_names, "Class")
feature_names
Boruta_features_data_without_tentative = get_top_features(feature_names = feature_names)
write.csv(Boruta_features_data_without_tentative, "Boruta_features_data_without_tentative.csv", row.names = FALSE)


# Plot variable importance
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")  
Boruta_features_data_without_tentative
tmp_data = createDataPartition(y = Boruta_features_data_without_tentative$Class, p = 0.7, list=FALSE)
train_sample_data = Boruta_features_data_without_tentative[tmp_data,]
test_sample_data = Boruta_features_data_without_tentative[-tmp_data,]


```


```{r - rpart - DONE}

##################################
# rpart model feature importance #
################################## 

rpart = train(Class ~ ., data=train_sample_data, method="rpart")
plot(rpart)
rpartImp = varImp(rpart)

rpart_features_data = get_top_features(rpart, 5)

feature_names = colnames(rpart_features_data)
feature_names = append(feature_names, "Class")

rpart_features_data = subset(train_data, select = feature_names)
write.csv(rpart_features_data, "rpart_features_data.csv", row.names = FALSE)

tmp_data = createDataPartition(y = rpart_features_data$Class, p = 0.7, list=FALSE)
train_sample_data = train_data[tmp_data,]
test_sample_data = train_data[-tmp_data,]

```


```{r - QVT - }




```


```{r - SVM Kernels - Done}
# best params {'C': 100, 'cache_size': 200, 'coef0': 0.7, 'gamma': 0.0001, 'kernel': 'poly', 'random_state': 0} rs 104



svm_model_poly = svm(Class ~ ., data = train_sample_data, kernel = "polynomial",
                     cost=100, coef0= 0.7, cachesize=200, gamma=0.0001, scale = TRUE) 

preds = predict(svm_model_poly, newdata = test_sample_data)
from_svm = preds
auc = Metrics::auc(tmp_test_sample$Class, preds)
auc
preds = pred_v2
preds = as.numeric(levels(preds))[preds]
preds
from_svm
get_test_metrics(test_sample_data, preds)

# test using kaggle dataset 
preds = predict(svm_model_poly, newdata = test_data)
get_data_for_kaggle_score(preds = preds)


#################
# svm_model_rbf #
#################

svm_model_rbf = svm(Class ~ ., data = train_sample_data, kernel = 'radial', scale = TRUE) # rbf
preds = predict(svm_model_rbf, test_sample_data, type="Class", scale = TRUE)

preds = as.numeric(levels(preds))[preds]

get_test_metrics(test_sample_data, preds)

# test using kaggle dataset 
preds = predict(svm_model_rbf, newdata = test_data)
get_data_for_kaggle_score(preds = preds)

####################
# svm_model_linear #
####################

svm_model_linear = svm(Class ~ ., data = train_sample_data, kernel = "linear", scale = TRUE)

preds = predict(svm_model_linear, test_sample_data, type="Class")


preds = as.numeric(levels(preds))[preds]

get_test_metrics(test_sample_data, preds)

# test using kaggle dataset 
preds = predict(svm_model_linear, newdata = test_data)
get_data_for_kaggle_score(preds = preds)


#####################
# svm_model_sigmoid #
#####################

svm_model_sigmoid = svm(Class ~ ., data = train_sample_data, kernel = "sigmoid", scale = TRUE)
preds = predict(svm_model_sigmoid, test_sample_data, type="Class")



preds = as.numeric(levels(preds))[preds]

get_test_metrics(test_sample_data, preds)

# test using kaggle dataset
preds = predict(svm_model_sigmoid, newdata = test_data)

get_data_for_kaggle_score(preds = preds)
```


```{r - get data}

#######################################
# data 70% - 20% split for train-test #
#######################################
train_data = mlsp_train

train_data = Boruta_features_data_without_tentative

train_data = LASSO_features_data

train_data = RFE_features_data

train_data = rpart_features_data

train_data = RRF_features_data


# get indices for 70% of the data set
train_data$Class = factor(train_data$Class) 
tmp_data = createDataPartition(y = train_data$Class, p = 0.7, list=FALSE)

# separate test and training sets
train_sample_data = train_data[tmp_data,]
test_sample_data = train_data[-tmp_data,]


```


```{r - DWD Kernels }

fitControl = trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)

###########
# dwdPoly #
###########
dwdPoly = train(Class ~ ., data = train_sample_data, method = "dwdPoly", trControl=fitControl)
preds = predict(dwdPoly, test_sample_data)
preds = as.numeric(levels(preds))[preds]
get_test_metrics(test_sample_data, preds)
preds = predict(dwdPoly, newdata = mlsp_test)
get_data_for_kaggle_score(preds = preds)


#############
# dwdRadial #
#############
dwdRadial = train(Class ~ ., data = train_sample_data, method = "dwdRadial", trControl=fitControl)
preds = predict(dwdRadial, test_sample_data)
preds = as.numeric(levels(preds))[preds]
get_test_metrics(test_sample_data, preds)
preds = predict(dwdPoly, newdata = mlsp_test)
get_data_for_kaggle_score(preds = preds)


#############
# dwdLinear #
#############
dwdLinear = train(Class ~ ., data = train_sample_data, method = "dwdLinear", trControl=fitControl)
preds = predict(dwdLinear, test_sample_data)
preds = as.numeric(levels(preds))[preds]
get_test_metrics(test_sample_data, preds)
preds = predict(dwdPoly, newdata = mlsp_test)
get_data_for_kaggle_score(preds = preds)


########
# sdwd #
########
sdwd = train(Class ~ ., data = train_sample_data, method = "sdwd", trControl=fitControl)
preds = predict(sdwd, test_sample_data)
preds = as.numeric(levels(preds))[preds]
get_test_metrics(test_sample_data, preds)
preds = predict(dwdPoly, newdata = mlsp_test)
get_data_for_kaggle_score(preds = preds)




```



```{r - kerndwd - cant collect metrics}

# Save references 
tmp_test_sample = test_sample_data
tmp_train_sample = train_sample_data

# restore references
test_sample_data = tmp_test_sample
train_sample_data = tmp_train_sample

size=20

# OLD FORMATING 
#x = as.matrix(data.frame(lapply(train_sample_data, as.numeric)))
#f = train_sample_data$Class
#y = as.numeric(levels(f))[f]

train_sample_data = data.frame(lapply(train_sample_data, as.numeric))
test_sample_data = data.frame(lapply(test_sample_data, as.numeric))

# REQUIRED format data for kern function, i guess?
# replace(test_sample_data$Class, test_sample_data$Class==0, -1)
# The order of conversion was wrong first 
test_sample_data$Class[test_sample_data$Class == 1] = 0
train_sample_data$Class[train_sample_data$Class == 1] = 0
test_sample_data$Class[test_sample_data$Class == 2] = 1
train_sample_data$Class[train_sample_data$Class == 2] = 1


test_sample_data$Class[test_sample_data$Class == 0] = -1
train_sample_data$Class[train_sample_data$Class == 0] = -1

####################
# fit a linear DWD #
####################
kern = vanilladot()
dim(train_sample_data)
dwd_linear = kerndwd(train_sample_data[1:size], train_sample_data$Class, kern, lambda = 1)

# why is the pred being squished down to [1:25 1:100] from 
train_sample_data = as.matrix(train_sample_data)
preds = predict(dwd_linear, kern, train_sample_data, test_sample_data)

# revert value sanitazation for model so results can be used for gathering metrics 

preds = replace(preds, preds==-1, 0)
test_sample_data$Class[test_sample_data$Class == -1] = 0
get_test_metrics(tmp_test_sample, preds)

# test using kaggle dataset 
new_Test = data.frame(lapply(test_data, as.numeric))
train_sample_data = as.matrix(train_sample_data)
preds_v3 = predict(dwd_linear, kern, train_sample_data, test_data)
preds_v3
get_data_for_kaggle_score(preds = preds_v3)


###################################
# fit a DWD using Gaussian kernel #
###################################

kern = rbfdot(sigma=1)
dwd_gaussian = kerndwd(train_sample_data[1:410], train_sample_data$Class, kern, lambda=1)
train_sample_data = as.matrix(train_sample_data)
test_sample_data
preds = predict(dwd_gaussian, kern, train_sample_data, test_sample_data)
preds

#############################
# fit a weighted kernel DWD #
#############################

kern = rbfdot(sigma=1)
weights = c(1, 2)[factor(train_sample_data$Class)]
dwd_weighted_gaussian = kerndwd(train_sample_data, train_sample_data$Class, kern, lambda=1, qval=1, wt = weights, eps=1e-5, maxit=1e5)
train_sample_data = as.matrix(train_sample_data)
test_sample_data
pred = predict(dwd_weighted_gaussian, kern, train_sample_data, test_sample_data)
pred
#########################
# fit polynomial kernel #
#########################

kern = polydot(degree = 1, scale = 1, offset = 1)
dwd_polynomial = kerndwd(x, y, kern, qval=1, eps=1e-5, maxit=1e5)
pred = predict(dwd_polynomial, kern, x, test_data)



# TODO https://discuss.analyticsvidhya.com/t/how-to-resolve-error-na-nan-inf-in-foreign-function-call-arg-6-in-knn/7280/3
# fit laplacian kernel -- Error in dwdpath(x, y, nobs, np, kern, qval, ulam, nlam, wt, eps, maxit, : NA/NaN/Inf in foreign function call (arg 2)
kern = laplacedot(sigma = 1)
dwd_laplacian = kerndwd(x, y, kern, qval=1, eps=1e-5, maxit=1e5)
pred = predict(dwd_laplacian, kern, x, test_data)


# fit bessel kernel -- Error in dwdpath(x, y, nobs, np, kern, qval, ulam, nlam, wt, eps, maxit, : NA/NaN/Inf in foreign function call (arg 2)
kern = besseldot(sigma = 1, order = 1, degree = 1)
nobs = nrow(test_data)
dwd_bessel = kerndwd(x, y, kern, qval=1, eps=1e-5, maxit=1e5)
pred = predict(dwd_bessel, kern, x, test_data)

#######################################################
# fit anova rbf kernel where rbf is a gaussian kernel #
#######################################################
kern = anovadot(sigma = 1, degree = 1)
dwd_anova = kerndwd(x, y, kern, qval=1, eps=1e-5, maxit=1e5)
pred = predict(dwd_anova, kern, x, test_data)

######################################################################
# fit spline kernel - Error: cannot allocate vector of size 106.8 Gb #
######################################################################
kern = splinedot()
dwd_spline = kerndwd(x, y, kern, qval=1, eps=1e-5, maxit=1e5)
pred = predict(dwd_spline, kern, x, test_data)


```

